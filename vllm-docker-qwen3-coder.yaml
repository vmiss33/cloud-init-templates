#cloud-config
# cloud-init to run vLLM Docker container with tool calling enabled
# This will start the vLLM service automatically on first boot
runcmd:
  - |
    set -euxo pipefail

    echo "[cloud-init] Waiting for Docker..."
    for i in $(seq 1 60); do
      docker info >/dev/null 2>&1 && break
      sleep 2
    done

    IMAGE="vllm/vllm-openai-rocm:v0.15.0-base"
    NAME="vllm"
    MODEL="Qwen/Qwen3-Coder-Next"

    docker pull "${IMAGE}"
    docker rm -f "${NAME}" || true

    docker run -d \
      --name "${NAME}" \
      --network=host \
      --ipc=host \
      --device /dev/kfd \
      --device /dev/dri \
      --group-add video \
      --restart=always \
      "${IMAGE}" \
      vllm serve "${MODEL}" \
        --max-model-len 32768 \
        --block-size 512 \
        --enable-auto-tool-choice \
        --tool-call-parser qwen3_coder

    echo "[cloud-init] vLLM up.  Logs: docker logs -f ${NAME}"